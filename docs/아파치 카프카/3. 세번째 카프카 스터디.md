3장 카프카 기본 개념 설명(3.4 ~ 3.5)
===================
1) 프로듀서 API
   * #### ProducerRecord를 생성하고 KafkaProducer의 send() 보내도록 정의 후 프로듀서 내부에 배치 형태로 묶여 있다가 전송(배치 전송)
     * #### 브로커로 전송할 때 내부적으로 파티셔너, 배치 생성 단계를 거친다.
     * #### send() 메소드가 호출되면 파티셔너가 어느 파티션으로 전송할 것인지 정해짐
     * #### 파티셔너를 지정하지 않으면 DefaultPartitioner로 설정됨
       * #### UniformStickyPartitioner(2.4부터 기본파티셔터임), RoundRobinPartitioner(2.3까지 기본파티셔너임)로 제공됨
         * #### 라운드로빈 방식은 레코드가 들어오는 대로 파티션을 순회하면서 배치로 묶이는 빈도가 적다. 
           많은 데이터를 배치로 묶어 전송하기 위해서 2.4부터는 UniformStickyPartitioner가 기본 파티셔너로 지정됨
     * #### 파티션이 정해지면 어큐뮬레이터에 데이터를 버퍼로 쌓아놓고 발송함(배치로 전송되면서 처리량을 향상시킴)
       * #### 센더(sender)스레드는 어큐뮬레이터에 쌓인 배치 데이터를 가져가 브로커로 전송함.
   * #### 압축하는 방식을 이용해 네트워크 처리량을 이득을 볼 수 있지만 압축하는 과정에서 리소스를 사용하게 되는 점을 주의해야 함
   * #### 프로듀서 api 주요옵션
     * #### acks : 성공여부 옵션 (1 - 기본값 : 리더 파티션만 성공 체크, 0 : 성공여부 판단 안 함, -1 : 리더 파티션과 팔로워 파티션에 저장 성공 판단)
     * #### buffer.memory : 브로커로 전송할 버퍼 메모량(기본은 32MB)
     * #### batch.size : 배치로 전송할 레코드 최대 용량(너무 작으면 네트워크 부담됨), 기본값 16384
     * #### partitioner.class : 레코드 파티션에 전송할 때 적용할 파티셔너 클래스 지정(기본값 : DefaultPartitioner)
   * #### 커스텀 파티셔너
     * #### 특정 키를 특정 파티션으로만 적재되게 할 수 있다.
     * #### Partitioner IF의 구현체를 만들어서 분기문을 작성하면 됨
     * #### ProducerConfig에 PARTITIONER_CLASS_CONFIG옵션을 커스텀 파티셔너 클래스로 저정하면 됨
   * #### 브로커 정상 전송 여부 확인
     * #### send() 메소드는 Future 객체를 반환함.
       * #### RecordMetadata의 비동기 결과를 표현한 것으로 producer.send(record).get()를 사용하면 브로커로부터 응답을 기다리며 대기 시간이 발생함(빠른 전송의 허들임)
     * #### 응답시간을 줄이기 위해서 비동기 결과를 확인할 수 있도록 Callback IF를 구현하면 된다.(onCompletion메소드는 결과 메시지 받기 위해 사용)
       * #### 예시 : producer.send(record, new ProducerCallback());
       * #### 비동기로 받으면 속도는 빨라지지만 전송하는 데이터 순서가 중요한 경우는 사용하면 안 된다.
         * #### 비동기로 대기를 타는 동안 다음 데이터가 전송 성공하고 대기 중인 메시지가 실패할 경우 재전송을 하게 되면서 데이터 순서가 역전됨

2) 컨슈머 API
   * #### 컨슈머 API를 구현시 컨슈머 그룹을 선언해야 하고 컨슈머 그룹의 컨슈머 오프셋을 기준으로 데이터를 처리함.
     * #### 컨슈머에 토픽을 할당하려면 subscribe() 메소드를 사용함
     * #### 무한루프 내부에서 poll() 메소드를 호출하여 데이터를 가져와서 계속 처리한다.
       * #### 반환값은 ConsumerRecord이다. 
   * #### 각 컨슈머 그룹으로 격리된 환경 제공
     * #### 서로 다른 저장소로 저장하는 경우 다른 컨슈머 그룹으로 격리하여 다른 저장소가 장애가 나도 장애 격리가 되어 안정성 확보할 수 있음 
     * #### 컨슈머 그룹으로 묶인 컨슈머가 토픽을 구독할 때 1개의 파티션은 최대 1개의 컨슈머 할당됨
     * #### 1개의 컨슈머는 여러 개의 파티션에 할당될 수 있음.
     * #### 3개의 파티션일 경우 4개의 컨슈머로 이루어진 컨슈머 그룹에서 1개의 컨슈머는 유휴상태로 남게됨.
   * #### 리밸런싱
     * #### 장애가 발생한 파티션은 정상인 컨슈머로 소유권을 넘긴다.
     * #### 리밸런싱 발생 2가지 상황
       * #### 컨슈머가 추가되는 상황과 컨슈머가 제외되는 상황임
     * #### 리밸런싱 발생할 때 파티션 소유권을 재할당하기 때문에 같은 그룹 내의 컨슈머들이 데이터를 읽을 수 없다.
       * #### 그룹조정자(Group coordinator)가 리밸런싱을 발동시키는 역할을 하는 데 컨슈머 추가/삭제를 감지함.(브로커 중 한 대가 그룹 조정자로 역할 수행함)
   * #### 어떤 컨슈머 그룹이 몇 번째 토픽 파티션을 몇 번 가져갔는지 브로커 내부에서 기록함(_consumer_offsets)
     * #### 오프셋 커밋 기록을 못했다면 데이터 중복 처리가 발생함. 그래서 오프셋 커밋을 정상적으로 처리했는지 검증해야 함
     * #### 오프셋 커밋 방식
       * #### 비명시적(디폴트값 enable.auto.commit=true, auto.commit.interval.ms(간격)) : 일정 간격마다 자동으로 커밋됨.
         * #### 커밋 관련 코드를 따로 작성할 필요 없어서 편리함(단점 : 리밸런싱 또는 컨슈머 강제종료 시 데이터 중복 혹은 유실 가능성 있음)
       * #### 명시적 : poll() 호출 이후에 반환받은 데이터의 처리 완료되고 commitSync() 메소드 호출
         * #### commitSync() 메소드는 브로커에 커밋 요청하고 정상 처리까지 응답을 기다림 그후에 데이터 처리함(단점 : 시간당 처리량이 줄어들음.) - 개별 커밋, 일괄 커밋 가능
           * #### 단점 해결 방안으로 commitAsync() 메소드를 사용함. (하지만 커밋 요청 실패 시 데이터 순서 보장이 않되며 데이터 중복 처리 발생함)
             * #### 비동기 콜백함수를 사용한다.(OffsetCommitCallBack의 onComplete()로 확인)
   * #### 컨슈머는 poll() 메소드를 통해 레코드를 반환받지만 호출 시점에 클러스터에서 바로 받는 것이 아님
     * #### 컨슈머 애플리케이션에 있는 Fetcher인스턴스가 생성되어 poll() 호출하기 전에 미리 내부 큐로 미리 가져고 poll호출 시 처리 수행함
   * #### 컨슈머 api 옵션
     * #### auto.offset.rest : 컨슈머 그룹이 특정 파티션을 읽을 때 저장된 컨슈머 오프셋이 없는 경우 어느 오프셋부터 읽을지 선택(lastest(기본값), earliest, none)
     * #### enable.auto.commit : 자동 커밋으로 할지 수동 커밋으로 할지 선택 (기본값 : true)
     * #### auto.commit.interval.ms : 자동 커밋일 경우 오프셋 커밋 간격(기본값 : 5000(5초))
     * #### max.poll.records : poll() 메소드를 통해 반환되는 레코드 개수
     * #### session.timeout.ms : 컨슈머가 브로커와 연결이 끊기는 최대 시간
       * #### 컨슈머가 heartbeat를 전송하지 않으면 브로커는 컨슈머가 이슈가 발생했다고 판단하고 리밸런싱을 시작
     * #### heartbeat.interval.ms : 하트비트를 전송하는 시간 간격(기본값 : 3000(3초))
     * #### isolation.level : 트랜잭션 프로듀서가 레코드를 트랜잭션 단위로 보낼 경우 사용
   * #### 리밸런스 리스너를 가진 컨슈머
     * #### 리밸런스 발생 시 데이터 중복 처리를 막기 위해 처리한 데이터 기준으로 커밋을 시도할 수 있음
       * #### 리밸런스 감지를 위해서는 ConsumerRebalanceListener IF를 구현해야 함
         * #### subscribe() 메소드에 오버라이드 변수로 리스터 포함시키면 됨(consumer.subscribe(토픽리스트, 커슈머리스너);) 
           * #### onPartitionAssigned() 메소드 : 리밸런스가 끝난 뒤에 파티션 할당이 완료되면 호출
           * #### onPartitionRevoked() 메소드 : 리밸런스가 시작되기 직전 호출하는 메소드
             * #### 메소드 내에서 consumer.commitSync를 호출하여 처리한 레코드 커밋 수행함.
   * #### 셧다운 훅(shutdown hook) : 사용자 또는 운영체제로부터 종료 요청을 받으면 실행되는 스레드
   * #### 카프카 종료 시 안전하게 종료하도록 wakeup() 메소드를 지원한다.
     * #### wakeup() 메소드를 호출되면 poll() 메소드가 호출되면서 WakeupException예외 발생하고 데이터 처리를 위한 사용 자원들을 해제한다.

3) 카프카 스트림즈
   * #### 토픽에 적재된 데이터를 상태기반 또는 비상태기반으로 실시간 변환하여 다른 토픽에 적재하는 라이브러리이다.
   * #### 스케줄링 불필요하며 카프카 클러스터로부터 토픽을 받아서 처리한다.
   * #### task : 스트림즈 데이터 처리 최소단위로 3개의 파티션으로 이루어진 토픽을 처리한다면 스트림즈 내부에 3개의 task가 생성됨.
     * #### 파티션이 늘어나면 task도 늘어나야 함
   * #### 안정성을 위해서 2개 이상의 서버로 구성하여 스트림즈 애플리케이션을 운영한다.
   * #### 토폴로지 : 2개 이상의 노드들과 선으로 이루어진 집합
     * #### 트리형, 성형, 링형이 있지만 스트림즈는 트리형과 유사함.
     * #### 프로세서 : 스트림즈에서 노드를 의미
       * #### 소스 프로세서 : 하나 이상의 토픽에서 데이터를 가져오는 역할
       * #### 스트림 프로세서 : 다른 프로세서가 반환하는 데이터를 처리하는 역할
       * #### 싱크 프로세서 : 처리한 데이터를 특정 토픽으로 저장하는 역할
     * #### 스트림 : 노드와 노드를 이은 선으로 스트림은 토픽 데이터를 의미함
   * #### 카프카 스트림즈는 스트림즈DSL(Domain Specific Language)와 프로세스 API 2가지 방식으로 개발 가능함.
     * #### 스트림즈DSL
       * #### KStream : 레코드의 흐름을 표현한 것으로 토픽에 존재하는 모든 레코드 출력(메시지키, 메시지값 구성됨)
       * #### KTable : KStream과 다르게 유니크한 메시지 키를 기준으로 가장 최신 레코드를 출력
       * #### GlobalKTable : KTable과 동일하게 메시지 키 기준으로 묶어서 사용함, 단 코파티셔닝이 안 되는 경우에 GlobalKtable로 사용됨.(KTable과 다르게 스트림즈 애플리케이션 모든 task에 동일하게 공유될 수 있기 때문)
         * #### 주의사항 : 모든 데이터를 저장하고 사용가능하기 때문에 스트림즈 애플리케이션의 로컬 스토리지 사용량이 증가하고 네트워크, 브로커에 부하가 생김 
           * #### 작은 용량만 사용하는 걸 권고하며 많은 양은 리파티셔닝을 통해서 KTable사용을 권장함.
         * #### 코파티셔닝 : 조인을 하는 2개의 데이터의 파티션 개수가 동일하고 파티셔닝 전략이 동일하게 맞추는 작업으로 동일할 경우 스트림즈 애플리케이션에서 동일한 task에 들어가 처리되는 것을 보장함
         * #### 코파티셔닝이 보장이 안 될 경우는 KStream과 KTable으로 조인을 걸고 싶어도 TopologyException 발생하여 스트림즈가 처리 못함
         * #### 리파티셔닝 : 새로운 토픽에 새로운 메시지 키를 가지도록 재배열하는 과정
       * #### stream() - 소스 프레세서, to() - 싱크 프로세서
         * #### stream() : 특정 토픽을 KStream형태로 가져오려면 스트림 DSL의 stream()를 사용함
         * #### to() : 특정 토픽으로 저장할 때 to()를 사용함
       * #### filter() - 싱크 프로세서 : 메시지 키 또는 값을 필터링하여 특정 조건에 맞는 데이터를 골라낼 때 사용
       * #### join() - 스트림 프로세서 : KStream과 KTable을 조인할 때 사용
         * #### 이벤트 데이터를 DB에 저장하지 않고도 조인하여 이벤트 기반 스트리밍 데이터 파이프라인을 구성 가능해짐
         * #### 코파티셔닝이 되어 있는지 확인 필요(조인 대상이 동일한 파티션 개수, 동일한 파티셔닝을 사용하는지 체크)
         * #### 코파티셔닝이 보장 안 되는 경우 GlobalKTable과 KStream join()
     * #### 프로세서 API
       * #### 스트림즈DSL은 데이터 처리, 분기, 조인을 위한 다양한 메소드를 제공하지만 추가적인 상세 로직을 구현이 필요한 경우는 프로세서 API를 사용한다.
       * #### 스트림즈DSL에서 사용했던 KStream, KTable, GlobalKTable 개념이 없다.
       * #### Topology클래스를 선언 후 addSource()를 사용하여 토픽을 가져오고 addProcessor()메소드를 사용하여 처리하고 addSink()메소를 사용하여 저장한다.
    
# 고민해볼 것 
 * #### RoundRobinPartitioner의 단점이 파티션을 순회하면서 배치 버퍼로 묶이는 빈도가 적다고 했는 데 좀 더 상세한 설명이 필요함.
 * #### 레코드를 압축하는 방식을 사용하여야 하는 사례들이 어떤 것들이 있을까? (정말 리소스를 많이 잡아 먹는 것일까?)
 * #### 우리 item-message-api는 프로듀서 acks 성공여부 옵션을 뭘로 하고 있을까? 찾아보자.
 * #### 프로듀서에서 브로커 정상 전송 여부 체크 우리는 동기식인가? 비동기식인가? 만약 비동기라면 실패 시 순서보장이 안 되는 어려움이 발생하고 있는 것일까?
 * #### 컨슈머 애플리케이션에서 Fetcher인스턴스가 생성되고 미리 레코드들을 큐에 쌓아 놓는데 그렇다면 미리 받는 기준과 쌓아놓는 메모리 사이즈는 어떻게 정해지는 것인가?
 * #### item-message-api는 자동커밋일까? 수동커밋일까?
 * #### 컨슈머가 브로커에게 heartbeat을 보낸다는 사실을 처음 알았고 예전에 카프카 장애 났을 때 왜 계속 재기동을 했는지 이해가 되었음
 * #### 리밸런스 리스너를 사용해서 리밸런스 감지를 하고 처리한 데이터를 onPartitionRevoked() 메소드 안에서 커밋치는 방안이 인상적임
 * #### 카프카 스트림즈에서 task의 개수와 파티션의 개수가 중요하고 코파티셔닝과 리파티셔닝의 의미가 인상적이었음.
 * #### KTable과 GlobalKTable의 차이점과 GlobalKTable 사용 시 주의할 점(모든 task에 공유됨)
 * #### 소스 프로세서, 스트림 프로세서, 싱크 프로세스의 의미가 재미있었음.
 * #### 스트림즈DSL과 프로세서API를 어떤 때 사용해야 할까? 그냥 프로세서 API를 쓰는 게 낫지 않을까?
 * #### 우리가 카프카스트림즈를 쓴다고 하면 어떤 서비스에 쓸 수 있을까? 재고 이력에는 쓸 수 없을까?