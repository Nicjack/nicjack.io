5장 카프카 실전 프로젝트(5.1 ~ 5.1.3)
===================
1) 웹 페이지 이벤트 적재 파이프라인 생성
   * #### 이벤트 수집은 서비스에 영향을 미치지 않으면서 안정적으로 유지 필요
     * #### 이벤트 데이터 파이프라인 : 이벤트 발생 -> 데이터 파이프라인 -> DB 
     * #### 이벤트 수집 파이프라인과 서비스의 커플링을 최소화하고 확정성 높은 파이프라인을 만드는 것이 중요
   * #### 정책 및 기능 정의
     * #### 적재정책
       * #### 유실 및 중복 가능할 경우(적어도 한번 이상 - at least once)
         * #### 0.11.0.0 이전 버전의 카프카
         * #### 이벤트 로그 같은 경우 네트워크 이슈로 유실될 수 있으나 추이는 확인 가능한 경우 사용
       * #### 유실 중복 없어야 하는 경우(정확히 한번 - exactly once)
         * #### 0.11.0.0 이후 버전의 카프카에서 멱등성 프로듀서로 정확히 전달
           * #### 멱등성 프로듀서는 고유한 키를 지원하는 DB에 적재하는 것이 가장 확실함(RDMS)
             * #### 고유 키를 가진 테이블을 사용해서 insert을 하면 중복해서 시도하더라도 중복 적재를 막을 수 있다.
           * #### 전달의 의미는 프로듀서 -> 브로커까지를 말한다.(적재와는 다른 개념)
       * #### 적재 : 프로듀서 -> 브로커 -> 컨슈머 -> DB까지 저장을 의미
         * #### <u>HDFS 적재, S3 적재는 컨슈머의 커밋과 저장이 동일 트랜잭션 처리 불가능하다.</u>
           * #### 장애 발생 시 정확히 적재를 못하기 때문에 이슈 발생 시점에 확인 > 특정 파티션, 특정 오프셋부터 다시 적재해야 함
     * #### 데이터 포맷
       * #### 파이프라인에서 데이터를 담는 용도로 사용
         * #### VO(Value Object)를 사용하여 직렬화하여 전송할 경우 문제점
           * #### 보편적이고 편하지만 동일한 버전의 VO객체를 선언해서 사용해야 함
           * #### 변수가 추가될 경우 프로듀서, 컨슈머 둘 다 소스코드 업데이트 필요하여 비용이 큼
           * #### kafka-console-consumer 명령어를 통해 출력할 경우 내부 데이터 확인할 수 없어서 디버깅이 어려움.
       * #### 데이터 포맷 선택 원칙
         * #### 스키마의 변화의 유연성
         * #### 명령어를 통한 디버깅 편리성
       * #### JSON(JavaScript Object Notation)은 String 또는 ByteArray로 직렬화하여 전송
         * #### kafka-console-consumer 명령어로 출려 가능
         * #### 스키마 변경에 유연하게 대처 가능
         * #### HDFS에서 JSON포맷으로 파일을 적재하면 아파치 하이브로 external table을 생성해서 SQL로 뽑아낼 수 있음.
         * #### 엘라스틱서치는 JSON 포맷 기반으로 문서 파일을 저장하기 때문에 포맷 변경 없이 데이터 적재 용이함.
     * #### 프로듀서
       * #### 이벤트를 REST API 클라이언트로 전달받아서 토픽을 전달함
         * #### RestController만들고 KafkaTemplate로 프로듀서 구현 후 데이터 전송
       * #### 생각해 볼 것
         * #### ack를 어떤 값으로 설정할 것인가?
           * #### all : 네트워크 문제시 복구될 확률이 가장 높지만 데이터를 저장하는 데에 시간이 오래 걸림
           * #### 0, 1 : all보다는 속도는 빠르지만 클러스터 이상시 데이터 복구 못하고 유실됨.
             * #### <U>일부 유실이 되더라도 안정적이고 빠른 파이프라인을 구성하려면 1을 설정한다.</U>
         * #### 최소 동기화 리플리카(min.insync.replicas) 설정은?
           * #### <U>ack를 1로 선택한 경우 min.insync.replicas설정을 무시하고 리더 파티션에 지속 적재하므로 최소동기화 설정 불필요함.</U>
           * #### <U>ack를 all설정으로 운영할 경우에만 토픽의 min.insync.replicas 설정 유효함.</U>
         * #### 파티션 설정은?
           * #### 메시지 키 또는 메시지 값 기반으로 어떤 파티션으로 전달할지 결정해야 한다.
           * #### 웹 페이지 생성된 파티션을 분류할 필요 없기 때문에 기본 파티셔너인 UniformStickyPartitioner 사용
         * #### 재시도(retryies) 설정은?
           * #### 장애로 인하여 정상 전송이 되지 않았을 경우 표로듀서는 다시 전송을 시도한다.
             * #### 단 재시도 시 중복 전송이 발생할 수 있다.(전송의 역전으로 인해 토픽의 적재 순서가 바뀔 수 있다.)
             * #### 웹 이벤트는 데이터 순서가 중요하지 않고 중복 허용이 가능
         * #### 압축 옵션 설정?
           * #### 압축을 하면 클러스터에 적재 데이터 용량을 줄이고 네트워크 사용량을 줄이는 데에 효과가 있음
           * #### 단 프로듀서, 컨슈머에서 데이터 사용 시 CPU, 메모리 사용량이 늘어나고 압축하지 않았을 때보다 처리량이 줄어들 수 있다.
     * #### 토픽
       * #### 파티션 개수?
         * #### 데이터 처리 순서를 지켜야 하는지에 따라 엄격하게 정할지 결정 필요.
           * #### 하둡 또는 엘라스틱에 데이터를 순서대로 적재하지 않아도 데이터에 이벤트 발생 시간을 조합해서 넣어 놓으면 적재순서와 이벤트 발생 시간이 달라도 여러 개의 파티션을 병렬로 컨슈머를 운영이 가능해짐.
             * #### 즉, 이벤트 발생 시간으로 재조합이 가능하다는 것임.
       * #### 메시지키 사용?
         * #### 메시지키를 사용하고 기본 파티셔너를 사용하면 키의 해시값으로 파티션이 분배된다.
           * #### 추후 파티션이 증가하면 해시값과 파티션의 매칭이 깨지기 때문에 특정 파티션으로 할당해서 운영해야 하는 컨슈머 운영은 어려워 짐.
           * #### 메시지 키를 사용하지 않으면 토픽에 들어오는 데이터양에 따라서 파티션 개수를 가변적으로 설정할 수 있다.
       * #### 복제 개수(replication factor) 설정은?
         * #### 복제 개수가 높으면 데이터 복구 확률이 높아짐.
         * #### 복제 개수가 너무 높으면 팔로워 파티션이 데이터 복제하는 데에 시간이 오래 걸릴 수 있으며 클러스터 전체 저장 데이터의 용량도 늘어남
         * #### 이벤트 파이프라인은 브로커 1대에 이슈가 발생하도 안정적으로 데이터를 받기 위해 최소 2로 설정한다.
     * #### 컨슈머 
       * #### 구현 방법
         * #### 첫 번째 : 컨슈머 API를 직접 애플리케이션을 개발하는 방법
         * #### 두 번째 : 커넥트를 사용하는 방법(분산 커넥트를 사용하면 REST API 통해서 커넥터로 반복적인 파이프라인을 쉽게 생성할 수 있다.)
           * #### 오픈소스 커넥트는 법적인 이슈 주의 필요
           * #### 직접 구현시 싱크 커넥터로 구현
   * #### 기능 구현
     * #### 사용자 이벤트 > REST API (프로듀서 APP) > 카프카 > 컨슈머 APP
     * #### 컨슈머 구현 시 하나의 프로세스에서 N개의 스레드로 N개의 파티션을 병렬처리 하도록 구현 가능하다.
     * #### HDFS 메시지 저장 방식
       * #### append 방식 : 파일을 생성하고 poll()로 데이터를 받아서 계속 추가한다. 단 기존 적재 파일에 문제가 생기면 append 할 수 없다.
       * #### flush 방식 : 일정 기간 데이터를 쌓고 저장하는 방식 단 파일 개수가 계속 늘어나고 컨슈머 APP에 메모리가 필요한 단점이 있다.
       * #### HDFS는 멀티 스레드 환경에서 여러 컨슈머가 동일한 HDFS파일에 접근을 시도한다면 교착 상태에 빠질 위험이 있다.
         * #### 교착 상태를 해결하기 위해서 파티션 번호에 따라 HDFS파일을 따로 저장하는 것이다. 파티션 번호는 assignment()메소드를 통해서 확인 가능
           * #### N개의 스레드 중 일부 컨슈머 스레드가 중단되더라도 파티션별로 파일을 접근하기 때문에 같은 스레드에서 동일 파일의 접근을 막을 수 있다.
     * #### 엘라스틱서치 싱크 커넥터 개발
       * #### ElasticSearchSinkConnectorConfig.java : 엘라스틱서치 저장에 필요한 설정 선언
       * #### ElasticSearchSinkConnector.java : 커넥터 생성했을 때 최초로 실행하며 태스크를 실행하기 위한 이전 단계로서 설정값을 확인하고 태스크 클래스 지정하는 역할 수행
       * #### ElasticSearchSinkTask.java : 실질적인 엘라스틱서치 적재 로직이 들어가며 적재 작업 수행
         * #### 엘라스틱서치에 적재하기 위해 RestHighLevelClient 인스턴스 생성한다.
         * #### 엘라스틱서치로 전송하기 위해서 BulkRequest 인스턴스 생성한다.
  
    
# 고민해볼 것 
* #### 데이터 포맷 선정 시 VO의 단점과 JSON의 장점이 인상적이었음.(알지만 복습 차원)
* #### 프로듀서 설정시 ack가 all로 설정이 되어 있을 때만 min.insync.replicas가 유효한지 다시 인지하게 되었음.
* #### 압축 옵션의 장단점을 명확하게 알게 되었음.
* #### 토픽과 파티션, 메시지 키 사용여부, 복제개수 대한 내용 복습할 수 있어 좋았음.
* #### HDFS와 엘라스틱서치에 대해서 맛보기로 알 수 있어 좋았음. 더 많이 공부해보고 싶었음.
