1장 들어가며
===================
1) 애플리케이션간 의존도를 최소화(커플링 완화)
2) 카프카 내부 동작은 FIFO방식이며 발행처는 프로듀서, 수신처는 커슈머라 함
3) 카프카는 최소 3대 이상의 브로커로 운영이 되어야 함(장애발생 대비)
    * #### 2대 이상으로 할 수는 없을까?
4) 데이터 레이크 : 서비스로부터 수집 가능한 모든 데이터를 모으는 것
5) 카프카 장점 : 높은 처리량(파티션 개수 = 커슈머 개수), 확장성(카프카 클러스터 스케일 OUT/IN), 영속성(파일시스템에 저장, PAGE CACHE영역을 메모리에 생성하여 I/O 성능확보), 고가용성(복제된 데이터가 다른 브로커도 저장하여 처리 가능)
6) 온프레미스(on-premise)-자체서버보유, 퍼블릭 클라우드(public cloud) 차이점
7) min.insync.replicas 값은 최소 2로 지정하고 브로커는 3대 이상이어야 함(2대 브로커가 복제를 보장하는 것을 의미하고 지속처리 가능)
    * #### 3대 일때 1대가 장애가 나더라도 운영할 수 있지만 2대만 운영할 때는 1대가 장애나면 토픽에 데이터를 넣을 수 없음.
8) 람다 아키텍처
    * #### 배치레이어(일괄처리), 스피드 레이어(실시간 분석), 서빙레이어(결과 데이터 USER 제공) 로 나뉘어서 운영
    * #### 장점 : 레거시 데이터 플로폼보다는 속도가 빠름
    * #### 단점 : 배치와 스피드 레이어가 2개로 나뉘어서 필요한 로직이 서로 나뉘어서 각각 처리하여 통합처리시 유연하지 못함.
9) 카파 아키텍처
    * #### 스피드레이어(실시간 분석), 서빙레이어(결과 데이터 USER제공)으로 나뉘어서 운영
    * #### 장점 : 시프드 레이어에서 데이터를 모두 처리할 수 있어 로직 파편화 해소 및 운영관리 용이성 확보
10) 스트리밍 데이터 레이크 아키텍처
    * ####  스피드레이어(실시간 분석 및 데이터 제공)만 운영(단일진실공급원 : SSOT)
    * ####  장점 : 서빙레이어로 데이터를 따로 저장할 필요성이 없다. (즉, 카프카에서 처리한 데이터를 장기간 저장함)
---       
2장 카프카 빠르게 시작해보기
===================
1) 저장 파일 유지 시간 지정 가능 : log.retention.hours보다는 log.retention.ms 사용 권고
2) 주키퍼 : 분산코디네이션 서비스를 제공하여 카프카 클러스터의 정보들을 담고 있음(카프카 실행시 필수 애플리케이션임)
3) 카프카 커맨드라인 툴 : 카프카 브로커 운영시 필요한 명령수행 툴임
   * ####  kafka-topics.sh : 토픽 생성(파티션 개수, 복제 개수, 토픽 데이터 유지 기간 옵션 지정 가능) / 토픽 수정 / 토픽 리스트 조회 가능(상세 포함)
   * ####  kafka-console-producer.sh : 메시지 전송
     * ####  토픽에 넣는 데이터를 레코드라고 지칭함(키와 메시지 값으로 구성)
     * ####  String 타입으로만 전송 가능(다른 타입은 불가)
     * ####  메시지 키가 존재하고 동일할 경우 동일한 파티션으로 전송됨(키에 대한 파티션 할당은 프로듀서의 파티셔너가 결정함)
     * ####  중간에 파티션 개수를 늘리면 동일한 키가 늘린 후에 동일한 파티션으로 간다고 보장 못함(보장하고 싶다면 커스텀 파티셔너를 직접 만들어야 함)
   * ####  kafka-console-consumer.sh : 메시지 수신 처리
     * ####  컨슈머 그룹을 통해 가져간 토픽의 메시지는 커밋 수행 : 특정 레코드의 오프셋 번호를 카프카 브로커에 저장(내부 토픽)하는 것임
     * ####  전송된 데이터가 출력되는 순서와 다름 : 파티션 때문에 나뉘어져서 동일하게 처리가 되기 때문에 발생
   * ####  kafka-consumer-groups.sh : 컨슈머 그룹 리스트 확인
     * ####  컨슈머 그룹은 따로 생성하지 않고 컨슈머가 동작할 때 지정하면 자동 생성됨(컨슈머 그룹 중복 주의)
     * ####  오프셋 : 파티션의 각 레코드에 할당된 번호
     * ####  랙(lag) : 컨슈머 그룹이 커밋한 오프셋과 해당 파티션이 가진 최신 오프셋 간의 차이
   * ####  kafka-verifiable-producer, consumer.sh : 카프카 클러스터 설치 후 코드 없이 간단한 통신 테스트용으로 사용
   * ####  kafka-delete-records.sh : 가장 오래된 데이터(오프셋 작은 것)부터 특정 시점의 오프셋까지 삭제 가능
     * ####  특정 데이터만 삭제는 불가함

# 고민해볼 것 
 * #### PAGE CACHE영역 확보로 파일시스템 I/O 성능 확보 어떻게 처리를 한 것일까?
 * #### min.insync.replicas 브로커 2대만으로도 운영할 방법이 없을까?
 * #### 1장 스트리밍 데이터 레이크 아키텍처는 정말 차기 카프카로 실현이 가능한 것일까?
 * #### 특정 레코드만 삭제할 수 있는 방법은 없는 것일까?
 * #### 컨슈머 그룹이 자동 생성되는 데 중복사용 체크를 할 수 있는 방법은 없을까?
 * #### LAG을 빨리 해결하기 위한 방법은?
 * #### 재고파트도 데이터 플로폼 아키텍처로 람다, 카파 아키텍처를 사용해서 재고를 처리할 수 있는 일은 없을까?
 * #### 온프레미스와 퍼블릭 클라우드 어떤 경우에 합리적으로 선택을 할 수 있을까?
 * #### 카프카를 사용하면서 느끼는 한계와 개선점은?